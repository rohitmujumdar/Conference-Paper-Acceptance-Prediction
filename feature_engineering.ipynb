{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_engineering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4a93a3c54ba941258815a33cdb408ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b8ba5d54fa4483f847bec31914d831d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7dc90b21b03d4be9949076d3f48c3496",
              "IPY_MODEL_44c70326c39c46a08f47119570360644"
            ]
          }
        },
        "0b8ba5d54fa4483f847bec31914d831d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dc90b21b03d4be9949076d3f48c3496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b97aab4d15c4e5a9f9f240b76178062",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 230,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 230,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16ffb354967447828e30b496b9089432"
          }
        },
        "44c70326c39c46a08f47119570360644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6765f30459b412bb97777c0d3f4390d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230/230 [00:01&lt;00:00, 124B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf02a6c1170940f39c51f462ace92fc6"
          }
        },
        "4b97aab4d15c4e5a9f9f240b76178062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16ffb354967447828e30b496b9089432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6765f30459b412bb97777c0d3f4390d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf02a6c1170940f39c51f462ace92fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkVwm0wDx49K",
        "colab_type": "code",
        "outputId": "b4b7f570-0c6a-4fb8-f884-8ede4a7122ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/data'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9co_p9hu6PbC",
        "colab_type": "code",
        "outputId": "d5b08c11-30de-4fd4-c3f0-9d25fb503160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFElHgUgsjLs",
        "colab_type": "code",
        "outputId": "be79fab1-cd48-4c2d-a65c-cbb8efcf55f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "pip install textstat"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.6/dist-packages (from textstat) (0.9.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp0mzIO5R42m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5479aed5-4f78-4476-8339-d08f2e6b62cb"
      },
      "source": [
        "pip install tqdm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.38.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2B3pCUH6InR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aec566a2-cb62-4299-b742-47d2312b7e78"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pandas.io.json import json_normalize\n",
        "import os\n",
        "import pandas.io.json as pd_json\n",
        "from collections import Counter,defaultdict\n",
        "import string\n",
        "import textstat\n",
        "import statistics\n",
        "import pickle\n",
        "import torch\n",
        "from transformers import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm import tqdm\n",
        "import difflib"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4iUEn56AoLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_affiliation_dictionary(author_university_df,university_score_df):\n",
        "\n",
        "    interim_mapper,mapper = {},{}\n",
        "    for index, row in author_university_df.iterrows():\n",
        "        #name,affiliation,homepage,scholarid\n",
        "        link = row['homepage']\n",
        "        try:\n",
        "            if \"http\" in link:\n",
        "                base = link.split(\"/\")[2]\n",
        "            else:\n",
        "                base = link.split(\"/\")[0]\n",
        "      \n",
        "            if \"www\" in base:\n",
        "                base = \".\".join(base.split(\".\")[1:])\n",
        "              \n",
        "            if base in interim_mapper:\n",
        "                if not row[\"affiliation\"] in interim_mapper[base]:\n",
        "                    interim_mapper[base][row[\"affiliation\"]] = 1\n",
        "                else:\n",
        "                    interim_mapper[base][row[\"affiliation\"]] += 1\n",
        "            else:\n",
        "                interim_mapper[base] = {}\n",
        "                interim_mapper[base][row[\"affiliation\"]] = 1\n",
        "              \n",
        "        except Exception as e:\n",
        "            print(\"Homepage : \",row['homepage'],\" defaulted!\")\n",
        "\n",
        "    # for base in interim_mapper:\n",
        "    #     if len( interim_mapper[base].keys()) > 1:\n",
        "    #         print(base, interim_mapper[base])\n",
        "\n",
        "    #interim_mapper now has the email ids, and number of times, they were refferred to as an affiliations.\n",
        "    #we ignore if number of affliations are more than 4 as then they are generic ids like gmail.com and shoudn't be mapped\n",
        "    #else we take the maximum\n",
        "\n",
        "    for base in interim_mapper:\n",
        "        if len(interim_mapper[base].keys()) < 2:\n",
        "            #calculate the maximum referred affiliation\n",
        "            max_count = 0\n",
        "            max_ff = \"\"\n",
        "            for aff in interim_mapper[base]:\n",
        "                if interim_mapper[base][aff] > max_count:\n",
        "                    max_count = interim_mapper[base][aff]\n",
        "                    max_ff = aff\n",
        "            mapper[base] = aff\n",
        "\n",
        "    '''with open(\"processed_data/affiliation_dict\", \"wb\") as output_file:\n",
        "        pickle.dump(mapper, output_file)'''\n",
        "\n",
        "    return mapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngM7MT6r8IbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_and_save_tfidf_model():\n",
        "\n",
        "    #collect corpus\n",
        "    corpus = []\n",
        "    directory_in_string = data_path + '/iclr_2017/train/parsed_pdfs'\n",
        "    directory_content = os.fsencode(directory_in_string)\n",
        "    for file in tqdm(os.listdir(directory_content)):\n",
        "        filename = os.fsdecode(file)\n",
        "        with open(os.path.join(directory_in_string, filename),encoding=\"utf8\") as file:\n",
        "            paper_metadata = json.load(file)['metadata']\n",
        "            abstract_text = paper_metadata['abstractText'].translate(punct_removal_table)\n",
        "            corpus.append(abstract_text)\n",
        "\n",
        "    vectorizer = TfidfVectorizer(analyzer='word', stop_words = stop_words)\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC2QB7Vd6WLM",
        "colab_type": "code",
        "outputId": "1cb264c1-4ede-46c6-d66a-7df99c5a0ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "4a93a3c54ba941258815a33cdb408ebe",
            "0b8ba5d54fa4483f847bec31914d831d",
            "7dc90b21b03d4be9949076d3f48c3496",
            "44c70326c39c46a08f47119570360644",
            "4b97aab4d15c4e5a9f9f240b76178062",
            "16ffb354967447828e30b496b9089432",
            "e6765f30459b412bb97777c0d3f4390d",
            "bf02a6c1170940f39c51f462ace92fc6"
          ]
        }
      },
      "source": [
        "#HOUSEKEEPING\n",
        "stop_words = stopwords.words('english')\n",
        "punct_removal_table = {ord(char): None for char in string.punctuation}\n",
        "\n",
        "MODELS = {\"BertModel\" : (BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
        "          \"OpenAIGPTModel\" : (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
        "          \"GPT2Model\" : (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n",
        "          \"TransfoXLModel\" : (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
        "          \"XLNetModel\" : (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
        "          \"XLMModel\" : (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
        "          \"DistilBertModel\" : (DistilBertModel, DistilBertTokenizer, 'distilbert-base-cased'),\n",
        "          \"RobertaModel\" : (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
        "          \"XLMRobertaModel\" : (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base')}\n",
        "model_class, tokenizer_class, pretrained_weights = MODELS['BertModel']\n",
        "#Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "nlp = pipeline('feature-extraction') \n",
        "\n",
        "#read author-affiliation file from csrankings hidden page \n",
        "author_university_df = pd.read_csv(os.path.join(data_path,\"author_university_list.csv\"))\n",
        "#read university-research score file from csrankings main page\n",
        "university_score_df = pd.read_csv(os.path.join(data_path,\"csrankings.csv\")).drop_duplicates(subset=['institute'])\n",
        "\n",
        "with open(os.path.join(data_path,'WordsFromTitleofTop200Papers.txt'),encoding=\"utf8\") as f:\n",
        "    top_200_titles_words_counter = Counter([word for word in f.read().translate(punct_removal_table).lower().split() if word not in stop_words])\n",
        "    #TAKE TOP 5%\n",
        "    top_200_titles_vocab = [key for key,value in top_200_titles_words_counter.most_common(int(0.05*len(top_200_titles_words_counter)))]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a93a3c54ba941258815a33cdb408ebe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=230, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVLM7Z7JQc3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "646f4f18-0d1e-4a54-f160-57649de8db12"
      },
      "source": [
        "email_institute_affiliation_mapper = build_affiliation_dictionary(author_university_df,university_score_df)\n",
        "tfidf_matrix = build_and_save_tfidf_model()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Homepage :  http:/roseyu.com  defaulted!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 349/349 [00:00<00:00, 502.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZJ--IHNpiKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_files_into_raw_df():\n",
        "\n",
        "    directory_in_string = data_path + '/iclr_2017/train/parsed_pdfs'\n",
        "    directory_content = os.fsencode(directory_in_string)\n",
        "    list_of_file_dicts,paper_data_df = [],pd.DataFrame()\n",
        "    file_number = 0\n",
        "    for file in tqdm(os.listdir(directory_content)):\n",
        "        filename = os.fsdecode(file)\n",
        "        file_dict = defaultdict()\n",
        "        #print(\"\\nOpening file : \",filename)\n",
        "        with open(os.path.join(directory_in_string, filename),encoding=\"utf8\") as file:\n",
        "            data = json.load(file)\n",
        "            file_dict['paper_id'] = data['name']\n",
        "            paper_metadata = data['metadata']\n",
        "\n",
        "            ################################ ABSTRACT ###################################################\n",
        "            #print(\"Extracting abstract features....\")\n",
        "            abstract_text = paper_metadata['abstractText'].translate(punct_removal_table).lower()\n",
        "            \n",
        "            #1. BERT et al encoding\n",
        "            '''input_ids = torch.tensor([tokenizer.encode(abstract_text)]).unsqueeze(0) \n",
        "            outputs = model(input_ids)\n",
        "            last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
        "            file_dict['attention_based_encoding'] = last_hidden_states[0][0]'''\n",
        "            file_dict['feature_extraction_encoding'] = nlp(abstract_text)[0][0] #DistilBERT\n",
        "            \n",
        "            #2. TFIDF ENCODING\n",
        "            file_dict['tfidf_encoding'] = tfidf_matrix.toarray()[file_number]\n",
        "            file_number = file_number + 1\n",
        "\n",
        "            #title = paper_metadata['title'].lower()\n",
        "            #3. IF ABSTRACT CONTAINS ATLEAST 2 WORDS FROM TOP 200 TITLES\n",
        "            if len(set(abstract_text.split()).intersection(set(top_200_titles_vocab))) > 2:\n",
        "                file_dict['words_from_top_200_title'] = True\n",
        "            else:\n",
        "                file_dict['words_from_top_200_title'] = False\n",
        "            \n",
        "            #4. ABSTRACT LENTGTH\n",
        "            file_dict['abstract_length'] = textstat.lexicon_count(abstract_text, removepunct=True)\n",
        "            \n",
        "            #5. ABSTRACT COMPLEXITY\n",
        "            flesch = 1/textstat.flesch_reading_ease(abstract_text)\n",
        "            dale_chall = textstat.dale_chall_readability_score(abstract_text)\n",
        "            file_dict['abstract_complexity'] = (flesch + dale_chall)/2\n",
        "\n",
        "            #6. ABSTRACT NOVELTY\n",
        "            if len({'outperforms','state-of-the-art','state of the art'}.intersection(set(abstract_text.split()))) > 0:\n",
        "                file_dict['abstract_novelty'] = True\n",
        "            else:\n",
        "                file_dict['abstract_novelty'] = False\n",
        "            ################################ TITLE ###################################################\n",
        "\n",
        "            ################################ AUTHORS ###################################################\n",
        "            #print(\"Extracting authors features.....\")\n",
        "            #1. NUMBER OF AUTHORS\n",
        "            reported_num_of_authors = len(paper_metadata['authors'])\n",
        "            if reported_num_of_authors == 0:\n",
        "                file_dict['number_of_authors'] = 2 #AVG?\n",
        "            else:\n",
        "                file_dict['number_of_authors'] = reported_num_of_authors\n",
        "            \n",
        "            #2. AUTHOR AFFILIATION SCORE\n",
        "            author_emails = paper_metadata['emails']\n",
        "            author_institutes = [email.split('@')[1] for email in author_emails]\n",
        "            research_strength_score = 0\n",
        "            if len(author_institutes) != 0:\n",
        "                for institute in author_institutes:\n",
        "                    closest_matches = difflib.get_close_matches(institute, email_institute_affiliation_mapper.keys())\n",
        "                    if len(closest_matches) == 0:\n",
        "                        #if there are no closest matches it's not from a university from our list, \n",
        "                        #which means its either a strange university or a corporate company. \n",
        "                        #either way its safe to give it a HIGH SCORE - even if the paper is not from a good source\n",
        "                        #other parameters will take care of it \n",
        "                        research_strength_score = research_strength_score + 60 #DECISION!\n",
        "                    else:\n",
        "                        affiliated_unis_from_string_match = [email_institute_affiliation_mapper[match] for match in closest_matches]\n",
        "                        sub_score = 0\n",
        "                        for affiliated_uni in affiliated_unis_from_string_match:\n",
        "                            try:\n",
        "                                sub_score = sub_score + university_score_df.loc[university_score_df.institute ==  affiliated_uni, 'count'].values[0]\n",
        "                            except Exception as e:\n",
        "                                #if it's an excpetion this is a university alright, \n",
        "                                #but doesnt fall in our 100 unis of csraniking scores\n",
        "                                #this means its mostly not a top uni, so it is safe to give it a LOW SCORE\n",
        "                                sub_score = sub_score + 6 #DECISION!\n",
        "                        closest_matches_avg_score = sub_score/len(affiliated_unis_from_string_match)\n",
        "                        research_strength_score = research_strength_score + closest_matches_avg_score\n",
        "                file_dict['research_strength_score'] = research_strength_score/len(author_institutes)                    \n",
        "            else:\n",
        "                file_dict['research_strength_score'] = 0\n",
        "            ################################ AUTHORS ###################################################\n",
        "\n",
        "            ################################ REFERENCES ###################################################\n",
        "            #print(\"Extracting references features.....\")\n",
        "            references_list,ref_mentions_list = paper_metadata['references'],paper_metadata['referenceMentions']\n",
        "            #1. NUM OF REFRERENCES\n",
        "            file_dict['num_of_references'] = len(references_list)\n",
        "            \n",
        "            #2. MOST RECENT REFERENCE YEAR\n",
        "            ref_years_list = [ref_dict['year'] for ref_dict in references_list]\n",
        "            file_dict['most_recent_ref_year'] = max(ref_years_list)\n",
        "            \n",
        "            #3. AVG LENGTH OF REF MENTION\n",
        "            if len(ref_mentions_list) != 0:\n",
        "                file_dict['avg_len_of_ref_mention'] = statistics.mean([ref_dict['endOffset'] - ref_dict['startOffset'] for ref_dict in ref_mentions_list])\n",
        "            else:\n",
        "                file_dict['avg_len_of_ref_mention'] = 0\n",
        "            \n",
        "            #4. NUMBER OF RECENT REFERENCES (current recent ref behnchmark = 4)\n",
        "            file_dict['num_of_recent_references'] = sum([1 for year in ref_years_list if paper_metadata['year']-year<4])\n",
        "            ################################ REFERENCES ###################################################\n",
        "                \n",
        "            ################################ CONTENT ###################################################\n",
        "            #print(\"Extracting content features.....\")\n",
        "            #content housekeeping\n",
        "            sections = paper_metadata['sections']\n",
        "            section_content = ''\n",
        "            for section in sections:\n",
        "                section_content = section_content + \" \" + section['text'].translate(punct_removal_table).lower()\n",
        "            file_dict['contains_githib_link'],file_dict['contains_appendix'] = False,False\n",
        "            \n",
        "            #1. NUMBER OF SECTIONS\n",
        "            file_dict['number_of_sections'] = len(sections)\n",
        "            \n",
        "            #2. CONTAINS GITHUB LINK\n",
        "            for section in sections:\n",
        "                if 'github' in section['text'].lower():\n",
        "                    file_dict['contains_githib_link'] = True\n",
        "                    break\n",
        "            \n",
        "            #3. READABILITY\n",
        "            flesch_score,dale_chall_score = 0,0\n",
        "            for section in sections:\n",
        "                flesch_score = flesch_score + textstat.flesch_reading_ease(section['text'])\n",
        "                dale_chall_score = dale_chall_score + textstat.dale_chall_readability_score(section['text'])\n",
        "            flesch_score,dale_chall_score = flesch_score/file_dict['number_of_sections'],dale_chall_score/file_dict['number_of_sections']  \n",
        "            file_dict['content_complexity'] = ((1/flesch_score) + dale_chall_score)/2\n",
        "            \n",
        "            #4. CONTAINS APPENDIX\n",
        "            for section in sections:\n",
        "                if section['heading'] is not None:\n",
        "                    if 'APPENDIX' in section['heading'] or section['heading'].split()[0] in set(string.ascii_uppercase):\n",
        "                        file_dict['contains_appendix'] = True\n",
        "                        break\n",
        "            \n",
        "            #5. NUMBER OF UNIQUE WORDS\n",
        "            file_dict['number_of_unique_words'] = len(Counter(section_content))\n",
        "            ################################ CONTENT ###################################################\n",
        "\n",
        "        list_of_file_dicts.append(file_dict)\n",
        "        #print(\"Closing file : \",filename)  \n",
        "    paper_data_df = pd.DataFrame(list_of_file_dicts)     \n",
        "    return paper_data_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r71uo5yiXrC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9d03a29f-8857-4920-cb7d-7f73b132c38a"
      },
      "source": [
        "paper_data_df = load_data_files_into_raw_df()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 349/349 [03:08<00:00,  1.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ZUGE9jpfIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "9348b683-d253-499a-e69e-201796178809"
      },
      "source": [
        "paper_data_df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>feature_extraction_encoding</th>\n",
              "      <th>tfidf_encoding</th>\n",
              "      <th>words_from_top_200_title</th>\n",
              "      <th>abstract_length</th>\n",
              "      <th>abstract_complexity</th>\n",
              "      <th>abstract_novelty</th>\n",
              "      <th>number_of_authors</th>\n",
              "      <th>research_strength_score</th>\n",
              "      <th>num_of_references</th>\n",
              "      <th>most_recent_ref_year</th>\n",
              "      <th>avg_len_of_ref_mention</th>\n",
              "      <th>num_of_recent_references</th>\n",
              "      <th>contains_githib_link</th>\n",
              "      <th>contains_appendix</th>\n",
              "      <th>number_of_sections</th>\n",
              "      <th>content_complexity</th>\n",
              "      <th>number_of_unique_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>305.pdf</td>\n",
              "      <td>[0.3867202699184418, -0.061806850135326385, -0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>198</td>\n",
              "      <td>9.676772</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>26</td>\n",
              "      <td>2016</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "      <td>3.984653</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>306.pdf</td>\n",
              "      <td>[0.4459645450115204, -0.025260714814066887, 0....</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>140</td>\n",
              "      <td>7.654289</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>32.066667</td>\n",
              "      <td>30</td>\n",
              "      <td>2016</td>\n",
              "      <td>109.228571</td>\n",
              "      <td>15</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>17</td>\n",
              "      <td>4.157808</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>304.pdf</td>\n",
              "      <td>[0.44415536522865295, -0.003114901017397642, 0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>136</td>\n",
              "      <td>8.265020</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>16.300000</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>90.833333</td>\n",
              "      <td>6</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>30</td>\n",
              "      <td>3.634356</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>307.pdf</td>\n",
              "      <td>[0.39931002259254456, 0.00502351950854063, -0....</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>False</td>\n",
              "      <td>163</td>\n",
              "      <td>8.715491</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>6.933333</td>\n",
              "      <td>34</td>\n",
              "      <td>2016</td>\n",
              "      <td>42.326531</td>\n",
              "      <td>22</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "      <td>4.365226</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>308.pdf</td>\n",
              "      <td>[0.3834475576877594, -0.032056376338005066, -0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>110</td>\n",
              "      <td>7.268245</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>13</td>\n",
              "      <td>2016</td>\n",
              "      <td>59.066667</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "      <td>3.705192</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>785.pdf</td>\n",
              "      <td>[0.41694310307502747, -0.045325443148612976, -...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>123</td>\n",
              "      <td>7.237888</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>19</td>\n",
              "      <td>2016</td>\n",
              "      <td>478.444444</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>11</td>\n",
              "      <td>3.582217</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>787.pdf</td>\n",
              "      <td>[0.43488961458206177, -0.06781546026468277, -0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>172</td>\n",
              "      <td>9.110834</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>21</td>\n",
              "      <td>2016</td>\n",
              "      <td>88.555556</td>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "      <td>4.333800</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>789.pdf</td>\n",
              "      <td>[0.40879935026168823, -0.025200681760907173, -...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>156</td>\n",
              "      <td>7.455183</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>7.133333</td>\n",
              "      <td>20</td>\n",
              "      <td>2016</td>\n",
              "      <td>154.459459</td>\n",
              "      <td>14</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>19</td>\n",
              "      <td>3.870994</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>790.pdf</td>\n",
              "      <td>[0.36916759610176086, -0.04860365390777588, -0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>119</td>\n",
              "      <td>6.816346</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26</td>\n",
              "      <td>2016</td>\n",
              "      <td>55.647059</td>\n",
              "      <td>20</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "      <td>4.281689</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>792.pdf</td>\n",
              "      <td>[0.3755916655063629, -0.025255238637328148, -0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>161</td>\n",
              "      <td>7.670020</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>32.600000</td>\n",
              "      <td>21</td>\n",
              "      <td>2016</td>\n",
              "      <td>18.294118</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>11</td>\n",
              "      <td>4.405931</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>349 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    paper_id  ... number_of_unique_words\n",
              "0    305.pdf  ...                     69\n",
              "1    306.pdf  ...                     52\n",
              "2    304.pdf  ...                     55\n",
              "3    307.pdf  ...                     49\n",
              "4    308.pdf  ...                     74\n",
              "..       ...  ...                    ...\n",
              "344  785.pdf  ...                     46\n",
              "345  787.pdf  ...                     66\n",
              "346  789.pdf  ...                     64\n",
              "347  790.pdf  ...                     52\n",
              "348  792.pdf  ...                     50\n",
              "\n",
              "[349 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}